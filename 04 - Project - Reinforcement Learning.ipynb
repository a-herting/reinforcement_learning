{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa880c3e",
   "metadata": {},
   "source": [
    "# Project: Reinforcement Learning\n",
    "- Bigger field - more learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b3c535",
   "metadata": {},
   "source": [
    "### Project field\n",
    "- Use Reinforcement Learning with Q-learning to find solutions to this field.\n",
    "![Field](img/field-2.png \"Field\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effaa2b7",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b576b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae15067",
   "metadata": {},
   "source": [
    "### Step 2: Create a field\n",
    "\n",
    "![Field](img/field-3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "632e66c7",
   "metadata": {},
   "source": [
    "- **__init__**:\n",
    "    - Use a list of list with integer values to represent all the states\n",
    "        - Goal end state should be 1, illegal states -1, other states 0\n",
    "    - Set the state to be random fo the size of states\n",
    "- **done**:\n",
    "    - Check if current state has non-negative values\n",
    "- **get_possible_actions**:\n",
    "    - Set a list to all possible actions **actions = [0, 1, 2, 3]**\n",
    "        - action = 0 is left\n",
    "        - action = 1 is right\n",
    "        - action = 2 is up\n",
    "        - action = 3 is down\n",
    "    - Then check if state is in a position where a possible actions should be removed.\n",
    "    - Finally, return the remaining actions\n",
    "- **update_next_state**:\n",
    "    - Get the current state\n",
    "    - Check if move is illegal, then return current state and -10 in reward\n",
    "    - Otherwise update state and return the reward according to new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "164623f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Field:\n",
    "    def __init__(self):\n",
    "        \n",
    "        #Initialize field and set a random start state\n",
    "        self.states = [[-1,0,0,0,0,0,0,0,0,0,0],\n",
    "                       [-1,0,0,0,0,0,0,1,0,0,0],\n",
    "                        [0,0,0,0,0,0,0,0,0,0,0]]\n",
    "        self.state = (random.randrange(0,len(self.states)),random.randrange(0,len(self.states[0])))\n",
    "        \n",
    "    def done(self):\n",
    "        #Check if it isn't in a neutral state\n",
    "        if self.states[self.state[0]][self.state[1]] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    # action: 0 => move left\n",
    "    # action: 1 => move right\n",
    "    # action: 2 => move up\n",
    "    # action: 3 => move down\n",
    "    \n",
    "    def get_possible_actions(self):\n",
    "        actions = [0,1,2,3]\n",
    "        if self.state[0] == 0:\n",
    "            actions.remove(2)\n",
    "        if self.state[0] == len(self.states)-1:\n",
    "            actions.remove(3)\n",
    "        if self.state[1] == 0:\n",
    "            actions.remove(0)\n",
    "        if self.state[1] == len(self.states[0])-1:\n",
    "            actions.remove(1)\n",
    "        return actions\n",
    "    def update_next_state(self,action):\n",
    "        x, y = self.state\n",
    "        if action == 0:\n",
    "            if y == 0:\n",
    "                return self.state,-10\n",
    "            self.state = x, y - 1  \n",
    "        if action == 1:\n",
    "            if y == len(self.states[0]) - 1:\n",
    "                return self.state, -1\n",
    "            self.state =  x, y + 1\n",
    "        if action == 2:\n",
    "            if x == 0:\n",
    "                return self.state, -10\n",
    "            self.state = x - 1, y\n",
    "        if action == 3:\n",
    "            if x == len(self.states) - 1:\n",
    "                return self.state, -10\n",
    "            self.state = x + 1, y\n",
    "        reward = self.states[self.state[0]][self.state[1]]\n",
    "        return self.state, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c22bc0a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2, 7), False, [0, 1, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field = Field()\n",
    "field.state, field.done(),field.get_possible_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72ab2df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7), 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field.update_next_state(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a3656443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1, 7), True, [0, 1, 2, 3])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field.state, field.done(),field.get_possible_actions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2cf74c6",
   "metadata": {},
   "source": [
    "### Step 3: Train the model\n",
    "- Create a $q$-table initialized to all 0\n",
    "    - Use **q_table = np.zeros(...)** *(insert values for ...)*\n",
    "- Set **alpha = .5, gamma = 0.5,** and **epsilon = 0.5**\n",
    "- Create *for*-loop iterating 10000\n",
    "    - Create new field\n",
    "    - While field not done\n",
    "        - Get possible actions and assign to **actions**\n",
    "        - With probability epsilon take a random action, otherwise take the best action\n",
    "            - HINT: **random.uniform(0, 1) < epsilon**\n",
    "            - HINT: Random action: **random.choice(actions)**, and best action: **np.argmax(q_table[field.state])**\n",
    "        - Get current state and assign it to **cur_x, cur_y**\n",
    "        - Update next state and get it and the reward\n",
    "        - Update **q_table[cur_x, cur_y, action] = (1 - alpha)*q_table[cur_x, cur_y, action] + alpha*(reward + gamma*np.max(q_table[next_x, next_y]))**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3c77d24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "field = Field()\n",
    "q_table = np.zeros((len(field.states),len(field.states[0]),4))\n",
    "\n",
    "alpha = .5\n",
    "gamma = .5\n",
    "epsilon = .5\n",
    "\n",
    "for _ in range(10000):\n",
    "    field = Field()\n",
    "    while not field.done():\n",
    "        actions = field.get_possible_actions()\n",
    "        if random.uniform(0,1) < epsilon:\n",
    "            action = random.choice(actions)\n",
    "        else:\n",
    "            action = np.argmax(q_table[field.state])\n",
    "        \n",
    "        cur_x, cur_y = field.state\n",
    "        (next_x,next_y),reward = field.update_next_state(action)\n",
    "        q_table[cur_x, cur_y, action] = (1 - alpha)*q_table[cur_x, cur_y, action] + alpha*(reward + gamma*np.max(q_table[next_x, next_y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cbc6c462",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00],\n",
       "        [-1.00000e+00,  1.56250e-02,  0.00000e+00,  1.56250e-02],\n",
       "        [ 7.81250e-03,  3.12500e-02,  0.00000e+00,  3.12500e-02],\n",
       "        [ 1.56250e-02,  6.25000e-02,  0.00000e+00,  6.25000e-02],\n",
       "        [ 3.12500e-02,  1.25000e-01,  0.00000e+00,  1.25000e-01],\n",
       "        [ 6.25000e-02,  2.50000e-01,  0.00000e+00,  2.50000e-01],\n",
       "        [ 1.25000e-01,  5.00000e-01,  0.00000e+00,  5.00000e-01],\n",
       "        [ 2.50000e-01,  2.50000e-01,  0.00000e+00,  1.00000e+00],\n",
       "        [ 5.00000e-01,  1.25000e-01,  0.00000e+00,  5.00000e-01],\n",
       "        [ 2.50000e-01,  6.25000e-02,  0.00000e+00,  2.50000e-01],\n",
       "        [ 1.25000e-01,  0.00000e+00,  0.00000e+00,  1.25000e-01]],\n",
       "\n",
       "       [[ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00],\n",
       "        [-1.00000e+00,  3.12500e-02,  7.81250e-03,  7.81250e-03],\n",
       "        [ 1.56250e-02,  6.25000e-02,  1.56250e-02,  1.56250e-02],\n",
       "        [ 3.12500e-02,  1.25000e-01,  3.12500e-02,  3.12500e-02],\n",
       "        [ 6.25000e-02,  2.50000e-01,  6.25000e-02,  6.25000e-02],\n",
       "        [ 1.25000e-01,  5.00000e-01,  1.25000e-01,  1.25000e-01],\n",
       "        [ 2.50000e-01,  1.00000e+00,  2.50000e-01,  2.50000e-01],\n",
       "        [ 0.00000e+00,  0.00000e+00,  0.00000e+00,  0.00000e+00],\n",
       "        [ 1.00000e+00,  2.50000e-01,  2.50000e-01,  2.50000e-01],\n",
       "        [ 5.00000e-01,  1.25000e-01,  1.25000e-01,  1.25000e-01],\n",
       "        [ 2.50000e-01,  0.00000e+00,  6.25000e-02,  6.25000e-02]],\n",
       "\n",
       "       [[-5.00000e+00,  7.81250e-03, -1.00000e+00,  0.00000e+00],\n",
       "        [ 3.90625e-03,  1.56250e-02,  1.56250e-02,  0.00000e+00],\n",
       "        [ 7.81250e-03,  3.12500e-02,  3.12500e-02,  0.00000e+00],\n",
       "        [ 1.56250e-02,  6.25000e-02,  6.25000e-02,  0.00000e+00],\n",
       "        [ 3.12500e-02,  1.25000e-01,  1.25000e-01,  0.00000e+00],\n",
       "        [ 6.25000e-02,  2.50000e-01,  2.50000e-01,  0.00000e+00],\n",
       "        [ 1.25000e-01,  5.00000e-01,  5.00000e-01,  0.00000e+00],\n",
       "        [ 2.50000e-01,  2.50000e-01,  1.00000e+00,  0.00000e+00],\n",
       "        [ 5.00000e-01,  1.25000e-01,  5.00000e-01,  0.00000e+00],\n",
       "        [ 2.50000e-01,  6.25000e-02,  2.50000e-01,  0.00000e+00],\n",
       "        [ 1.25000e-01,  0.00000e+00,  1.25000e-01,  0.00000e+00]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d9654e",
   "metadata": {},
   "source": [
    "### Step 4: Solve a task\n",
    "- To see the path make a variable **path = np.zeros((3, 11))**\n",
    "- Create a field **Field()**\n",
    "- To count steps assign **steps = 1**\n",
    "- Assign the start state in the path to **np.nan**.\n",
    "- The we begin: while not solved.\n",
    "    - Get the **action** to take\n",
    "    - Get the next **state**\n",
    "    - Update **path** with **steps**\n",
    "    - Increment **steps** with one\n",
    "- see the **path**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7034c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = np.zeros((3,11))\n",
    "field = Field()\n",
    "steps = 1\n",
    "path[field.state[0]][field.state[1]] = np.nan\n",
    "\n",
    "while not field.done():\n",
    "    action = np.argmax(q_table[field.state])\n",
    "    (next_x,next_y),_ = field.update_next_state(action)\n",
    "    path[next_x][next_y] = steps\n",
    "    \n",
    "    steps += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f585c2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  3.,  2.,  1., nan],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  4.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021fd13f",
   "metadata": {},
   "source": [
    "> ### Note\n",
    "> - The training phase (Step 3) could just take random actions\n",
    "> - Our example (Step 4) does not learn anything new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0c9589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "746800f96ece29ab8b5df47a779cb8f76655f7cf39bc7615a93fb17b55f50443"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
