# Reinforcement Learning Project

Given the field below, I used reinforcement learning with Q-learning to find solutions to the field within Jupyter notebook.

![enter image description here](https://github.com/LearnPythonWithRune/MachineLearningWithPython/raw/4c01affa620e139fe8a3f540690e4b72b569bdb0/jupyter/starter/img/field-2.png)

***Reinforcement learning*** is a one of three areas under machine learning that allows the agent to find the path with the maximum amount of reward. 

 1. The environment gives the agent a state. 
 2. The agent takes an action specific to the state (what's possible). 
 3. The environment provides the agent with a state and reward (positive or negative). 
 4. The agent takes an action specific to the state (what's possible). 

Actions are decisions that the agent can learn, while state is useful for helping the agent choose an action. 

***Markov's Decision Process*** is used to create the decision-making model to represent states, actions, and the agent's rewards. 
 -  Set of states ğ‘†

-   Set of actions ğ´ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ (ğ‘ )

-   Transition model ğ‘ƒ(ğ‘ â€²|ğ‘ ,ğ‘)

-   Reward function ğ‘…(ğ‘ ,ğ‘,ğ‘ â€²)


***Q-learning Model*** is the method used for learning a function ***Q(s , a)*** which is used to generate/update a table that estimates the value of performing an action ***a*** in state ***s***. 
 -  Set of states ğ‘†

-   Set of actions ğ´ğ‘ğ‘¡ğ‘–ğ‘œğ‘›ğ‘ (ğ‘ )

-   Transition model ğ‘ƒ(ğ‘ â€²|ğ‘ ,ğ‘)

-   Reward function ğ‘…(ğ‘ ,ğ‘,ğ‘ â€²)

**Q-learning**
-   Start with **ğ‘„(ğ‘ ,ğ‘) = 0** for all **ğ‘ ,ğ‘**
-   Update **ğ‘„** when we take an action
-   **ğ‘„(ğ‘ ,ğ‘)** = ğ‘„(ğ‘ ,ğ‘) + ğ›¼(reward + ğ›¾max(ğ‘ â€²,ğ‘â€²) âˆ’ ğ‘„(ğ‘ ,ğ‘)) = (1âˆ’ğ›¼)ğ‘„(ğ‘ ,ğ‘) + ğ›¼(reward + ğ›¾max(ğ‘ â€²,ğ‘â€²))

Additional information on reinforcement learning can be [found here](https://towardsdatascience.com/reinforcement-learning-101-e24b50e1d292).
Additional information from the reinforcement course can be [found here](https://www.youtube.com/watch?v=CGP0oV1kcJw&list=PLvMRWNpDTNwQZkB840U2d9JFXcA8spGMF&index=5). 
